# -*- coding: utf-8 -*-
# @Time    : 2018/1/5 17:38
# @Author  : zhangxinhe
# @File    : video_parser.py
import sys
import cv2
import time
import tensorflow as tf
import threading
import thread
from multiprocessing import Queue, Pool

from managers.config_manager import ConfigManager
from modules.comm.msg import MsgFactory
from modules.comm.msg_code_define import MsgCodeEnum
from managers.path_manager import PathManager
from modules.gate.gate_status import Gate
from modules.gate.gate_status import GateOperationEnum
from modules.frame.frame_manager import FrameManager
from modules.frame.frame import Frame
from libs.utils.frame_parser import parse_origin_video_frame
from libs.utils.frame_parser import item_detect
from libs.utils.app_utils import FPS, WebcamVideoStream
from libs.utils.decorator import coroutine

from managers.component_manager import ComponentManager

# Loading label map
label_map = ComponentManager.get_label_map()
categories = ComponentManager.get_categories()

class VideoParser(object):
    def __init__(self):
        self.__lock = threading.Lock()
        self.__video_name = 'Video' + str(ConfigManager.get_sources())
        self.__queue_size = ConfigManager.get_queue_size()
        self.__input_q = None
        self.__output_q = None
        self.__width = ConfigManager.get_width()
        self.__height = ConfigManager.get_height()
        self.__gate = Gate.get_instance()
        self.__gate.add_status_observer(GateOperationEnum.GATE_OPEN, self.__on_gate_begin_open)
        self.__gate.add_status_observer(GateOperationEnum.GATE_CLOSE, self.__on_gate_begin_close)
        # self.__video_stream = WebcamVideoStream(ConfigManager.get_sources(),
        #                                         ConfigManager.get_width(),
        #                                         ConfigManager.get_height()).start()
        # self.__fps = self.__video_stream.stream.get(cv2.CAP_PROP_FPS)
        # self.__expose = self.__video_stream.stream.get(cv2.CAP_PROP_EXPOSURE)
        # print "fps: ", self.__fps
        # print "expose_value: ", self.__expose
        # self.__video_stream.stream.set(cv2.CAP_PROP_EXPOSURE, -6)
        # print "expose_value: ", self.__video_stream.stream.get(cv2.CAP_PROP_EXPOSURE)
        #
        # self.__detection_graph = tf.Graph()
        # self.__init_session()
        self.__gate_opened = False
        self.__cur_frame_manager = None
        # self.__co_thread = None
        self.__frame_sn = 0

    def __send_result(self, detect_item):
        msg = MsgFactory.get_msg(MsgCodeEnum.MSG_REPORT_RESULT_REQ)
        msg.set_items(detect_item)
        msg.send()

    def __pool_worker(self, in_queue, out_queue, frame_manager):
        # Load a (frozen) Tensorflow model into memory.
        detection_graph = tf.Graph()
        with detection_graph.as_default():
            od_graph_def = tf.GraphDef()
            with tf.gfile.GFile(PathManager.get_ckpt_path(), 'rb') as fid:
                serialized_graph = fid.read()
                od_graph_def.ParseFromString(serialized_graph)
                tf.import_graph_def(od_graph_def, name='')

            sess = tf.Session(graph=detection_graph)

        width = ConfigManager.get_width()
        height = ConfigManager.get_height()
        category_index = ComponentManager.get_category_index()

        input_q = in_queue
        output_q = out_queue

        i = 0
        n = 0
        t = time.time()

        while self.__gate_opened:
            frame = input_q.get()

            n += 1
            now = time.time()
            if now - t > 1:
                print "hand FPS: ", n, " time: ", now - t,
                print " input_q: ", self.__input_q.qsize(), " output_q: ", self.__output_q.qsize(),
                print " max_qsize: ", self.__queue_size
                t = now
                n = 0

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            if True:
                updated_frame, score, classes, boxes = parse_origin_video_frame(frame_rgb,
                                                                                sess,
                                                                                detection_graph,
                                                                                category_index)
                items = item_detect(score, classes, boxes, category_index)

                if items:
                    valid_frame = Frame()
                    # print "items: ",
                    for item in items:
                        # print item.get_id(), item.get_name(), item.get_score(), width - item.get_x(), height - item.get_y(),
                        valid_frame.add_item(item)
                    # print " end"
                    frame_manager.add_frame(valid_frame)
            else:
                updated_frame = frame_rgb

            i += 1
            output_q.put(updated_frame)

        #self.__cur_frame_manager.print_item()
        sess.close()

    def __handle_frame_thread(self, name, id):
        # parse_frame = self.__parse_origin_frame()
        # self.__read_frame(parse_frame)
        print "width: ", self.__width, " height: ", self.__height
        self.__input_q = Queue(maxsize=self.__queue_size)
        self.__output_q = Queue(maxsize=self.__queue_size)
        self.__cur_frame_manager = FrameManager(self.__width, self.__height)
        self.__pool = Pool(ConfigManager.get_worker_num(), self.__pool_worker, (self.__input_q, self.__output_q, self.__cur_frame_manager))

        video_capture = WebcamVideoStream(ConfigManager.get_sources(),
                                          ConfigManager.get_width(),
                                          ConfigManager.get_height()).start()
        fps = FPS().start()

        n = 0
        t = time.time()

        while self.__gate_opened:
            origin_frame = video_capture.read()

            n += 1
            now = time.time()
            if now - t > 1:
                print "read FPS: ", n, " time: ", now - t,
                print " input_q: ", self.__input_q.qsize(), " output_q: ", self.__output_q.qsize(),
                print " max_qsize: ", self.__queue_size
                t = now
                n = 0

            self.__input_q.put(origin_frame)

            output_rgb = cv2.cvtColor(self.__output_q.get(), cv2.COLOR_RGB2BGR)
            cv2.imshow(self.__video_name, output_rgb)
            fps.update()
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        fps.stop()
        video_capture.stop()

        #self.__cur_frame_manager.print_item()
        self.__cur_frame_manager.parse_frame()
        self.__send_result(self.__cur_frame_manager.get_detect_item())
        self.__cur_frame_manager = None
        self.__input_q = None
        self.__output_q = None
        # self.__pool.terminate()
        # sys.exit()

    def __on_gate_begin_open(self):
        # with self.__lock:
        self.__gate_opened = True
        print "gate opened. started a thread!"
        self.__frame_sn = 0
        self.__handle_frame_thread = thread.start_new_thread(self.__handle_frame_thread, ("handle_frame_thread", "1"))

    def __on_gate_begin_close(self):
        print "gate closed"
        self.__gate_opened = False

    # def __read_frame(self, target):
    #     while self.__gate_opened:
    #         frame = self.__input_q.get()
    #         target.send(frame)
    #     else:
    #         target.close()
    #
    # @coroutine
    # def __parse_origin_frame(self):
    #     try:
    #         while True:
    #             frame = (yield)
    #             if frame is None:
    #                 continue
    #
    #             category_index = ComponentManager.get_category_index()
    #             updated_frame, score, classes,boxes = parse_origin_video_frame(frame,
    #                                                                            self.__session,
    #                                                                            self.__detection_graph,
    #                                                                            category_index)
    #             items = item_detect(score, classes, boxes, category_index)
    #             if items:
    #                 valid_frame = Frame()
    #                 print "items: ",
    #                 for item in items:
    #                     print item.get_id(), item.get_name(), item.get_score(), self.__width - item.get_x(), self.__height - item.get_y(),
    #                     valid_frame.add_item(item)
    #                 print " end"
    #                 self.__cur_frame_manager.add_frame(valid_frame)
    #
    #             self.__output_q.put(frame)
    #     except GeneratorExit:
    #         with self.__lock:
    #             self.__cur_frame_manager.parse_frame()
    #             self.__send_result(self.__cur_frame_manager.get_detect_item())
    #             self.__cur_frame_manager = None
